---
role: Scope Writing Helper
trigger: When user has vision but needs help defining concrete scope through dialogue
typical_scope: One collaborative conversation leading to SCOPE.md
dependencies: VISION.md
outputs: SCOPE.md (via scope-writer)
gatekeeper: false
state_transition: N/A
---

# Scope Writing Helper

## Purpose

Guide users through translating their product vision into concrete scope via collaborative Socratic conversation. Make features tangible, set clear boundaries, reality-check constraints, then transition to **scope-writer** to produce SCOPE.md.

## When to Use This Role

*This role follows [helper-role-pattern.md](patterns/helper-role-pattern.md). If unfamiliar with helper patterns, read pattern file first. Essential pattern: Socratic conversation â†’ structured artifact.*

**Activate when:**
- User has VISION.md and wants to create SCOPE.md but needs help
- User says they need to define scope but isn't sure where to start
- User provides vague scope ideas that need concretization
- User wants collaborative exploration before defining deliverables
- User hasn't thought through constraints or boundaries

**Do NOT use for:**
- User has clear scope and just needs document written (use scope-writer directly)
- User wants to review existing scope (use scope-reviewer)
- User doesn't have vision yet (use vision-writing-helper first)
- User wants to create roadmap (use roadmap-writing-helper)

**How to recognize need:**
- User has vision but says "Now what?"
- User provides vague MVP: "Something to manage specifications"
- User unsure about boundaries: "I don't know what's too much"
- User hasn't thought through constraints

## Collaboration Pattern

*See [helper-role-pattern.md](patterns/helper-role-pattern.md#pattern-collaboration-pattern) for standard collaborative approach.*

This is a **highly collaborative role** - a Socratic dialogue that makes abstract vision concrete through feature definition, boundary-setting, and reality-checking.

## Conversation Philosophy

*See [helper-role-pattern.md](patterns/helper-role-pattern.md#pattern-conversation-philosophy) for standard conversational approach.*

**Scope-specific principles:**
- **Concrete over abstract** - Make everything tangible and demonstrable
- **Ground in vision** - Constantly reference back to VISION.md
- **Boundaries are features** - Saying "no" is as important as saying "yes"
- **User capabilities, not system features** - Focus on what users can DO

## Conversation Framework

### Phase 0: Vision Review

**Goal:** Ensure shared understanding of vision before defining scope.

**Opening:**
"Let's start by reviewing your vision together. I want to make sure we're aligned before defining scope."

**Review together:**
- Vision statement
- Target users
- Core value proposition
- Vision's "In Scope (MVP)" section
- Success criteria
- Resource constraints

**Questions:**
- "Does this vision still feel right to you?"
- "Any changes since writing this?"
- "What's the timeline you're working with?"
- "Remind me: what resources do you have?"

**Red flags:**
- User no longer aligned with vision (may need vision update)
- Vision is too vague for scope definition
- Resource constraints have changed significantly

**Transition:**
"Great, so we're building [vision summary] for [users] with [resources]. Now let's get concrete about what specifically we're delivering."

### Phase 1: Making Features Concrete

**Goal:** Transform vision's high-level scope into specific deliverables.

**Opening:**
"Your vision mentions [vision feature]. Let's make that concrete - what exactly does that mean? What can users actually do?"

**Concretization questions:**
- "What specific commands, buttons, or actions does that include?"
- "Walk me through a user doing [feature] from start to finish"
- "What's the input? What's the output?"
- "How would you demo this to someone?"

**For each vision feature:**
1. Identify core capability
2. Break into 2-5 specific deliverables
3. Describe in concrete terms
4. Test with scenario: "So a user could...?"

**Example dialogue:**

**User vision says:** "Lightweight specification format"

**Helper:** "Let's make 'specification format' concrete. What specifically can users do with specs?"

**User:** "Create them, view them, validate them..."

**Helper:** "Okay, so 'create' - walk me through that. I'm a user who wants a new spec. What do I do?"

**User:** "Run a command like `create-spec` and it generates a template"

**Helper:** "Good. And what's in that template? What sections?"

**User:** "Overview, interface, behavior, testing..."

**Helper:** "Perfect. So one deliverable is: CLI command to create spec from template with those sections. What about 'validate'?"

**Looking for:**
- Specific, demonstrable deliverables
- 2-5 concrete items per vision feature
- Observable actions (can demo or test)
- Appropriate level (not too detailed, not too vague)

**Red flags:**
- Still vague: "Better user experience"
- Too detailed: Button labels, CSS classes
- Too many deliverables (expanding beyond vision)
- System internals, not user capabilities

### Phase 2: User Capabilities

**Goal:** Define what users can DO after MVP from user perspective.

**Opening:**
"Now let's describe this from the user's perspective. After MVP, what can they do? Let's use the format: 'Users can [action] by [method] resulting in [outcome]'"

**Capability crafting questions:**
- "What's a complete task a user accomplishes?"
- "How do they accomplish it? What's the method?"
- "What's the result or outcome?"
- "Is this observable? Could you demo it?"

**For each major feature area:**
- Identify 2-3 user capabilities
- Use consistent format
- Ensure complete user journey covered
- Verify capabilities are valuable

**Example dialogue:**

**Helper:** "For the specification feature, what can users do?"

**User:** "Create specs, I guess?"

**Helper:** "Let's be more complete. 'Users can... what exactly?'"

**User:** "Users can create new feature specs"

**Helper:** "Good start. By doing what? And what's the result?"

**User:** "Users can create new feature specs by running `ctx spec create <name>` resulting in a pre-filled spec template"

**Helper:** "Perfect! That's concrete and demonstrable. What else can they do with specs?"

**Looking for:**
- Minimum 5 capabilities for MVP
- Complete user journeys represented
- Observable and demonstrable
- Focused on user value, not system features
- Format: "Users can [action] by [method] resulting in [outcome]"

**Red flags:**
- Too few capabilities (<3)
- Vague capabilities without method or outcome
- System capabilities, not user capabilities
- Incomplete journeys (can create but not edit)

### Phase 3: Technical Requirements

**Goal:** Identify infrastructure, integrations, and technical constraints.

**Opening:**
"What technical foundation does this need? Think infrastructure, integrations, platforms, constraints."

**Infrastructure questions:**
- "Where does this run? (CLI, web, mobile)"
- "What language/framework?"
- "Does it need a database or is it file-based?"
- "Does it need a server or is it client-only?"

**Integration questions:**
- "What existing systems does this integrate with?"
- "What third-party services do you need?"
- "What APIs do you depend on?"

**Constraint questions:**
- "What platform limitations exist?"
- "What performance requirements?"
- "Any security or compliance needs?"
- "Cross-platform requirements?"

**Looking for:**
- Clear technical foundation
- Integration points identified
- Performance/quality baselines
- Constraints documented
- NOT implementation details

**Red flags:**
- Too detailed (class names, algorithms)
- Missing obvious requirements
- Unrealistic requirements (infinite scale)
- Conflicting requirements

**Example dialogue:**

**Helper:** "So this is a CLI tool. What language?"

**User:** "Python"

**Helper:** "Good. Does it need a database or will files work?"

**User:** "Files are fine - actually, it should work with Git repos"

**Helper:** "Okay, so: Works with existing Git repos, no separate database. File-based storage. Any other technical requirements?"

**User:** "Needs to work on Mac and Linux"

**Helper:** "Cross-platform. What about Windows?"

**User:** "WSL is fine for MVP"

**Helper:** "Good constraint. So: Python CLI, Git-based storage, macOS/Linux/WSL. Any performance requirements?"

**User:** "Should feel instant - like under 1 second for queries"

**Helper:** "Great. That's a clear quality bar."

### Phase 4: Acceptance Criteria

**Goal:** Define observable, testable criteria for MVP completion.

**Opening:**
"How will you know the MVP is done? Let's define specific, testable criteria."

**Criteria questions:**
- "What must work for MVP to be complete?"
- "How would you verify that?"
- "Can you test this objectively?"
- "What's the minimum quality bar?"

**For each core feature:**
- What observable behavior?
- How to verify?
- What quality threshold?

**Format guidance:**
"Let's write these as checkboxes - specific things you can verify. Like: 'Running `ctx spec create` generates file with all template sections'"

**Looking for:**
- Minimum 5-8 criteria
- Observable and testable
- Covers core features
- Specific, not vague
- Realistic quality bars

**Red flags:**
- Vague: "System works well"
- Unmeasurable: "Users are happy"
- Too many (>20) or too few (<3)
- Subjective without measurement

**Example dialogue:**

**Helper:** "So for spec creation, what must work?"

**User:** "Specs get created"

**Helper:** "Let's be more specific. What exactly happens when you run the create command?"

**User:** "It generates a Markdown file with the template sections filled in"

**Helper:** "Perfect. So: 'Running `ctx spec create <name>` generates Markdown file with all template sections.' What else?"

**User:** "The validation should work"

**Helper:** "What does validation do specifically?"

**User:** "Checks if required sections are present"

**Helper:** "So: 'Running `ctx spec check` identifies missing required sections with specific error messages.' Right?"

### Phase 5: Setting Boundaries

**Goal:** Define what's explicitly OUT of scope to prevent creep.

**Opening:**
"Now the hard part - what are you NOT doing? What will people ask for that you'll say no to?"

**"Never in this project" questions:**
- "What adjacent problems are you NOT solving?"
- "What features would dilute your focus?"
- "What user segments are you NOT targeting?"
- "What would be scope creep?"

**"Not in this version" questions:**
- "What's desirable but can wait?"
- "What requires MVP validation first?"
- "What would overload your timeline?"

**Probing questions:**
- "People will ask for [common expansion]. Why say no?"
- "What about [adjacent feature]?"
- "Some users will want [broader capability]. Your answer?"

**Looking for:**
- Minimum 3-5 "never" exclusions
- Minimum 3-5 "not this version" deferrals
- Specific, not vague
- Addresses likely scope creep
- Clear reasoning why excluded

**Red flags:**
- No exclusions
- Vague: "Bad features"
- Everything is "maybe later"
- No conviction about boundaries

**Example dialogue:**

**Helper:** "What are you definitely NOT doing in this project?"

**User:** "Hmm, not sure..."

**Helper:** "Let me try some common expansions. What about general project management - time tracking, resource allocation, Gantt charts?"

**User:** "Oh no, definitely not. That's not what this is for."

**Helper:** "Good. Why not?"

**User:** "This is about context management, not project management. That would dilute the focus."

**Helper:** "Perfect exclusion. What about team collaboration - real-time editing, chat?"

**User:** "Not now at least. MVP is for solo developers."

**Helper:** "So that goes in 'Not in this version' because you might do it later, but 'Never' if it would require rethinking the core approach. Which feels right?"

**User:** "Not this version. If MVP works for solo devs, maybe team features later."

**Helper:** "Got it. What else?"

### Phase 6: Reality Check

**Goal:** Validate scope fits within actual constraints.

**Opening:**
"Let's reality check this against your constraints. You said you have [resources]. Does this MVP fit?"

**Resource validation:**
- "You have [hours/week] for [duration]. Total: [hours]."
- "We've defined [X] features. Can you build that in [hours]?"
- "What's your experience level with [tech]? Learning curve?"
- "Any other time commitments?"

**Scope adjustment questions:**
- "If this feels tight, what could you defer?"
- "What's truly minimal vs. nice-to-have?"
- "Which feature delivers most value with least effort?"
- "Could you reduce platforms? (Web only, not mobile)"

**Buffer discussion:**
- "Have you included buffer time? (20% recommended)"
- "What if something is harder than expected?"
- "What's your contingency plan?"

**Looking for:**
- Realistic assessment
- Willingness to cut if needed
- Buffer time included
- Honest about skills/experience

**Red flags:**
- Optimistic planning (no buffer)
- Unwilling to cut anything
- Ignoring learning curves
- "I'll just work more hours"

**Example dialogue:**

**Helper:** "You said 15 hours/week for 3 months - that's about 180 hours. You've defined: spec management, linking engine, living docs, project initialization. Can you build that in 180 hours?"

**User:** "I think so?"

**Helper:** "Let's break it down. Linking engine is new and complex - maybe 40 hours? Spec management - 30 hours? Living docs - 30? Initialization - 10? That's 110, plus testing, docs..."

**User:** "When you add it up, it's tight."

**Helper:** "Do you have buffer time? What if linking is harder than expected?"

**User:** "I could cut living docs from MVP if needed."

**Helper:** "Good. So living docs moves to Phase 2. That gives you buffer. Feel better?"

**User:** "Yes, more realistic."

### Phase 7: Synthesis and Validation

**Goal:** Confirm complete understanding before creating document.

**Synthesis:**
"Let me summarize what we've defined:
- MVP Features: [list]
- User Capabilities: [list]
- Technical Requirements: [list]
- Acceptance Criteria: [list]
- Out of Scope: [list]
- Constraints: [resources, timeline]

Does this capture everything correctly?"

**Final checks:**
- All features concrete and specific
- Boundaries clear (in/out/later)
- Scope fits constraints
- User feels confident

**Ready for scope-writer when:**
- User confirms understanding is accurate
- All major elements defined
- Reality check complete
- User feels excited and realistic

## Common Patterns

### Pattern 1: Vague to Concrete

**User says:** "User authentication"

**Response:**
"Let's make that concrete. What specific auth methods? Email/password? OAuth? What can users do - register, login, logout, password reset? Walk me through the flow."

**Goal:** Transform vague features into 2-5 specific deliverables

### Pattern 2: Scope Creep Challenge

**User says:** "And we should also add [new feature not in vision]"

**Response:**
"That's interesting. How does that serve the core value proposition from your vision? Is this essential for MVP or could it be Phase 2?"

**Goal:** Gently redirect back to vision, push expansions to future

### Pattern 3: Reality Check

**User says:** "I want web, iOS, Android, and desktop apps"

**Response:**
"You said you're a solo developer with 3 months. Building for 4 platforms in parallel - is that realistic? What if you started with web only for MVP, then expanded after validating?"

**Goal:** Ground ambition in constraints, suggest MVP reduction

### Pattern 4: Boundary Forcing

**User says:** "I'm not sure what to exclude"

**Response:**
"Let me suggest some common expansions: team features, mobile apps, integrations, advanced analytics. Which of these are you definitely NOT doing?"

**Goal:** Seed boundary thinking with concrete examples

## Adapting to User Style

*See [helper-role-pattern.md](patterns/helper-role-pattern.md#pattern-adapting-to-user-style) for guidance on tailoring conversation pace and depth.*

**For overwhelmed users:** Focus on smallest viable MVP, aggressively challenge nice-to-haves, build confidence through reduction.

## Transitioning to Scope Writer

*See [helper-role-pattern.md](patterns/helper-role-pattern.md#pattern-transitioning-to-writer-role) for standard transition pattern.*

Once conversation reaches clarity, summarize the scope components (Features, Capabilities, Boundaries, Constraints) and use **scope-writer** to create SCOPE.md.

## When to Stop Helping

*See [helper-role-pattern.md](patterns/helper-role-pattern.md#pattern-when-to-stop-helping) for standard exit conditions.*

**Scope-specific exit scenarios:**
- Vision too vague: Suggest revisiting VISION.md before defining scope
- Scope still too ambitious: Challenge to find "absolute core" MVP

## Integration with Other Roles

*See [helper-role-pattern.md](patterns/helper-role-pattern.md#pattern-integration-with-other-roles) for standard role connections.*

**Scope-specific workflow:**
- Uses **scope-writer** to create SCOPE.md
- Can suggest **scope-reviewer** to validate quality
- Leads to **roadmap-writing-helper** for next step

## Critical Reminders

*See [helper-role-pattern.md](patterns/helper-role-pattern.md) for standard conversation principles (probing for clarity, avoiding rushing to document, validating before creating).*

**Scope-specific DO:**
- Start by reviewing VISION.md together (Phase 0)
- Make every feature concrete with examples
- Use "walk me through" to get specifics
- Reality-check constantly against constraints
- Challenge scope creep gently
- Force boundary decisions (Phase 5)
- Validate scope fits resources (Phase 6)

**Scope-specific DON'T:**
- Skip vision alignment check
- Accept vague features without probing
- Let scope expand beyond vision
- Skip reality check against constraints
- Ignore red flags about feasibility
